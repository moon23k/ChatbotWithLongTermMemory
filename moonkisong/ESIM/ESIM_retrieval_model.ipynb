{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ESIM_retrieval_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMKmsZEafiqUvqJWTnnv69h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4_xzg1tnSR6C"},"source":["## ESIM 모델을 pytorch 버전으로 간단하게 구현해보기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZG8UakhVO877","executionInfo":{"status":"ok","timestamp":1632619870422,"user_tz":-540,"elapsed":21235,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"73ebf6b3-cfd4-4792-9351-9916c5bceb85"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wd8MPAppPCs6","executionInfo":{"status":"ok","timestamp":1632620084003,"user_tz":-540,"elapsed":327,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"d866287d-b429-49c0-b65f-1007d3df90c1"},"source":["%cd /content/drive/MyDrive/Projs/ESIM/test"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projs/ESIM/test\n"]}]},{"cell_type":"markdown","metadata":{"id":"bDBOlc1RSX1n"},"source":["### Import Modules in Need"]},{"cell_type":"code","metadata":{"id":"SBBQ7IEmSHty","executionInfo":{"status":"ok","timestamp":1632620090248,"user_tz":-540,"elapsed":2463,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["import os\n","import collections\n","\n","import numpy as np\n","import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from data_iterator import TextIterator"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GNjY7A51nNM","executionInfo":{"status":"ok","timestamp":1632620092191,"user_tz":-540,"elapsed":313,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["#dir setting\n","data_path = '/content/drive/MyDrive/Data/ESIM_data/'\n","train_file = os.path.join(data_path, 'ubuntu_data_concat/train.txt')\n","valid_file = os.path.join(data_path, 'ubuntu_data_concat/valid.txt')\n","test_file = os.path.join(data_path, 'ubuntu_data_concat/test.txt')\n","vocab_file = os.path.join(data_path, 'ubuntu_data_concat/vocab.txt')\n","output_dir = '/rst'\n","embedding_file = os.path.join(data_path, 'embedding_w2v_d300.txt')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#args setting\n","hidden_size = 300\n","dim_word = 300\n","patience=1\n","vocab_size = 100000\n","batch_size = 16\n","epochs = 50\n","num_labels = 2\n","learning_rate = 2e-4\n","\n","max_buffer_size = 128 * 20\n","maxlen_1 = 400\n","maxlen_2 = 150"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8fFxM49S2Nr"},"source":["### Helper Functions"]},{"cell_type":"code","metadata":{"id":"Gg7lyYCzS0nN","executionInfo":{"status":"ok","timestamp":1632620098232,"user_tz":-540,"elapsed":312,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["def prepare_data(transformed_samples, maxlen_1=maxlen_1, maxlen_2=maxlen_2):\n","    \"\"\" padding the data with minibatch\n","    Args:\n","        instance: [list, list, list] for [labels, seqs_x, seqs_y]\n","    Return:\n","        c: int64 numpy.array of shape [seq_length_x, batch_size].\n","        c_mask: float32 numpy.array of shape [seq_length_x, batch_size].\n","        r: int64 numpy.array of shape [seq_length_y, batch_size].\n","        r_mask: float32 numpy.array of shape [seq_length_y, batch_size].\n","        l: int64 numpy.array of shape [batch_size, ].\n","    \"\"\"\n","    seqs_c = []\n","    seqs_r = []\n","    labels = []\n","\n","    for sample in transformed_samples:\n","        labels.append(sample[0])\n","        seqs_c.append(sample[1])\n","        seqs_r.append(sample[2])\n","\n","    lengths_c = [len(s) for s in seqs_c]\n","    lengths_r = [len(s) for s in seqs_r]\n","\n","    new_seqs_c = []\n","    new_seqs_r = []\n","    new_lengths_c = []\n","    new_lengths_r = []\n","    new_labels = []\n","\n","    for l_c, s_c, l_r, s_r, l in zip(lengths_c, seqs_c, lengths_r, seqs_r, labels):\n","        if l_c > maxlen_1:\n","            new_seqs_c.append(s_c[-maxlen_1:])\n","            new_lengths_c.append(maxlen_1)\n","        else:\n","            new_seqs_c.append(s_c)\n","            new_lengths_c.append(l_c)\n","        if l_r > maxlen_2:\n","            new_seqs_r.append(s_r[:maxlen_2])\n","            new_lengths_r.append(maxlen_2)\n","        else:\n","            new_seqs_r.append(s_r)\n","            new_lengths_r.append(l_r)\n","\n","        new_labels.append(l)\n","\n","    lengths_c = new_lengths_c\n","    seqs_c = new_seqs_c\n","    lengths_r = new_lengths_r\n","    seqs_r = new_seqs_r\n","    labels = new_labels\n","\n","    if len(lengths_c) < 1 or len(lengths_r) < 1:\n","        return None\n","\n","    n_samples = len(seqs_c)\n","    maxlen_1 = np.max(lengths_c)\n","    maxlen_2 = np.max(lengths_r)\n","\n","    c = np.zeros((maxlen_1, n_samples)).astype(\"float32\")\n","    r = np.zeros((maxlen_2, n_samples)).astype(\"float32\")\n","    c_mask = np.zeros((maxlen_1, n_samples)).astype(\"float32\")\n","    r_mask = np.zeros((maxlen_2, n_samples)).astype(\"float32\")\n","    l = np.zeros((n_samples,)).astype(\"float32\")\n","\n","    for idx, (s_c, s_r, ll) in enumerate(zip(seqs_c, seqs_r, labels)):\n","        c[:lengths_c[idx], idx] = s_c\n","        c_mask[:lengths_c[idx], idx] = 1.\n","        r[:lengths_r[idx], idx] = s_r\n","        r_mask[:lengths_r[idx], idx] = 1.\n","        l[idx] = ll\n","\n","    return (c, c_mask, r, r_mask, l)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDzqk_dL4p7_","executionInfo":{"status":"ok","timestamp":1632620102837,"user_tz":-540,"elapsed":316,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["def load_word_embedding(token_to_idx):\n","    embedding_np = 0.02 * np.random.randn(vocab_size, dim_word).astype(\"float32\")\n","\n","    if embedding_file:\n","        with open(embedding_file, \"r\") as f:\n","            for line in f:\n","                tokens = line.strip().split(\" \")\n","                token = tokens[0]\n","                vector = list(map(float, tokens[1:]))\n","                if token in token_to_idx and token_to_idx[token] < vocab_size:\n","                    embedding_np[token_to_idx[token], :] = vector\n","\n","    embedding = torch.Tensor(embedding_np)\n","    return embedding"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXyNy6WhXCEw","executionInfo":{"status":"ok","timestamp":1632620111131,"user_tz":-540,"elapsed":311,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["def load_vocab(vocab_file):\n","    vocab = collections.OrderedDict()\n","    index = 0\n","    with open(vocab_file, \"r\") as f:\n","        while True:\n","            token = f.readline()\n","            if not token:\n","                break\n","            token = token.strip()\n","            vocab[token] = index\n","            index += 1\n","    return vocab"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"9I9EBFPN3f5O","executionInfo":{"status":"ok","timestamp":1632641556604,"user_tz":-540,"elapsed":309,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["def local_inference(c, c_mask, r, r_mask):\n","    \"\"\"Local inference collected over sequences\n","    Args:\n","        c :      float32 Tensor of shape [seq_length1, batch_size, dim]\n","        c_mask : float32 Tensor of shape [seq_length1, batch_size]\n","        r :      float32 Tensor of shape [seq_length2, batch_size, dim]\n","        r_mask : float32 Tensor of shape [seq_length2, batch_size]\n","    \n","    Return:\n","        c_dual: float32 Tensor of shape [seq_length1, batch_size, dim]\n","        r_dual: float32 Tensor of shape [seq_length2, batch_size, dim]\n","    \"\"\"\n","\n","    # c :      [batch_size, seq_length1, dim]\n","    # c_mask : [batch_size, seq_length1]\n","    # r :      [batch_size, seq_length2, dim]\n","    # r_mask : [batch_size, seq_length2]\n","    c = torch.permute(c, [1, 0, 2]).contiguous()\n","    c_mask = torch.permute(c_mask, [1, 0]).contiguous()\n","    r = torch.permute(r, [1, 0, 2]).contiguous()\n","    r_mask = torch.permute(r_mask, [1, 0]).contiguous()\n","\n","    # attention_weight: [batch_size, seq_length1, seq_length2]\n","    attention_weight = torch.matmul(c, torch.permute(r, [0, 2, 1]).contiguous())\n","\n","    # calculate normalized attention weight x1 and x2\n","    # attention_weight_2: [batch_size, seq_length1, seq_length2]\n","    attention_weight_2 = torch.exp(attention_weight - torch.max(attention_weight, 2, keepdim=True).values)\n","    attention_weight_2 = attention_weight_2 * torch.unsqueeze(r_mask, 1)\n","\n","    # alpha: [batch_size, seq_length1, seq_length2]\n","    alpha = attention_weight_2 / (torch.sum(attention_weight_2, -1, keepdim=True) + 1e-8)\n","\n","    # c_dual: [batch_size, seq_length1, dim]\n","    c_dual = torch.sum(torch.unsqueeze(r, 1) * torch.unsqueeze(alpha, -1), 2)\n","\n","    # x1_dual: [seq_length1, batch_size, dim]\n","    c_dual = torch.permute(c_dual, [1, 0, 2])\n","\n","    # attention_weight_1: [batch_size, seq_length2, seq_length1]\n","    attention_weight_1 = attention_weight - torch.max(attention_weight, 1, keepdim=True)\n","    attention_weight_1 = torch.exp(torch.permute(attention_weight_1, [0, 2, 1]))\n","    attention_weight_1 = attention_weight_1 * torch.unsqueeze(c_mask, 1)\n","\n","\n","    # beta: [batch_size, seq_length2, seq_length1]\n","    beta = attention_weight_1 / (torch.sum(attention_weight_1, -1, keepdim=True) + 1e-8)\n","    \n","    # r_dual: [batch_size, seq_length2, dim]\n","    r_dual = torch.sum(torch.unsqueeze(c, 1) * torch.unsqueeze(beta, -1), 2)\n","    \n","    # r_dual: [seq_length2, batch_size, dim]\n","    r_dual = torch.permute(r_dual, [1, 0, 2])\n","\n","    return (c_dual, r_dual)"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"uohcQn6aSkdP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdu-pWJUudU9"},"source":["### Eval Functions"]},{"cell_type":"code","metadata":{"id":"LEM0KGkHBVnl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OMpvb6GBWlT"},"source":["### Model Class"]},{"cell_type":"code","metadata":{"id":"z_idnrsrxE6h","executionInfo":{"status":"ok","timestamp":1632622031077,"user_tz":-540,"elapsed":311,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["class ESIM(torch.nn.Module):\n","    def __init__(self, hidden_size, dropout, embedding):\n","        super(ESIM, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.emb = nn.Embedding.from_pretrained(embedding)\n","\n","        self.bilstm = nn.LSTM(input_size=dim_word, hidden_size=hidden_size * 2, bidirectional=True)\n","        \n","        #for dimension reduction\n","        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n","\n","        self.mlp = nn.Linear() #one-hidden-layer, tanh activation, softmax\n","        \n","        self.softmax = nn.Softmax(dim=1)\n","        self.dropout = nn.Dropout()\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, c, r, c_mask, r_mask):\n","#embedding part\n","        emb1 = self.emb(c)\n","        emb2 = self.emb(r)\n","\n","        emb1 = self.dropout(emb1, 1)\n","        emb2 = self.dropout(emb1, 1)\n","\n","        emb1 = emb1 * torch.unsqueeze(c_mask, -1)\n","        emb2 = emb2 * torch.unsqueeze(r_mask, -1)\n","\n","#encoding part        \n","        enc1, _ = self.bilstm(emb1)\n","        enc2, _ = self.bilstm(emb1)\n","\n","        enc1 = enc1 * torch.unsqueeze(c_mask, -1)\n","        enc2 = enc2 * torch.unsqueeze(r_mask, -1)\n","\n","#Matching Part\n","        #Local Inference\n","        dual1, dual2 = local_inference(enc1, c_mask, enc2, r_mask)\n","        c_match = torch.cat([enc1, dual1, enc1 * dual1, enc1 - dual1], dim=2)\n","        r_match = torch.cat([enc2, dual2, enc2 * dual2, enc2 - dual2], dim=2)\n","\n","        #Dimension Reduction with FC and dropout\n","        c_match_mapping = self.fc(c_match)\n","        r_match_mapping = self.fc(r_match)\n","\n","        c_match_mapping = self.dropout(c_match_mapping, dropout=dropout)\n","        r_match_mapping = self.dropout(r_match_mapping, dropout=dropout)\n","\n","        #Matching Compositioon\n","        c_cmp = self.bilstm(c_match_mapping, 1, args.hidden_size)\n","        r_cmp = self.bilstm(r_match_mapping, 1, args.hidden_size)\n","\n","        \n","        #logit calc\n","        logit_c_sum = torch.sum(c_cmp * torch.unsqueeze(c_mask, -1), 0) / \\\n","                        torch.unsqueeze(torch.sum(c_mask, 0), 1)\n","        logit_c_max = torch.max(c_cmp * torch.unsqueeze(c_mask, -1), 0)\n","\n","        logit_r_sum = torch.sum(r_cmp * torch.unsqueeze(r_mask, -1), 0) / \\\n","                        torch.unsqueeze(torch.sum(r_mask, 0), 1)\n","        logit_r_max = torch.max(r_cmp * torch.unsqueeze(r_mask, -1), 0)\n","\n","        logit = torch.cat([logit_c_sum, logit_c_max, logit_r_sum, logit_r_max], 1)\n","\n","        #Get Binary prediction (final out)\n","        logit = self.dropout(logit)\n","        logit = self.fc(logit)\n","        logit = self.dropout(logit)\n","        out = self.softmax(out)\n","        \n","        return out"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-V1VKgWBrG9"},"source":["### Unit Test"]},{"cell_type":"code","metadata":{"id":"XTrS9exMOZuB","executionInfo":{"status":"ok","timestamp":1632621899401,"user_tz":-540,"elapsed":1860,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["token_to_idx = load_vocab(vocab_file)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vm2mc-QkOfhH","executionInfo":{"status":"ok","timestamp":1632621916002,"user_tz":-540,"elapsed":15045,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["embedding = load_word_embedding(token_to_idx)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYm2bAmNTm_4","executionInfo":{"status":"ok","timestamp":1632621925911,"user_tz":-540,"elapsed":314,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["train = TextIterator(train_file, token_to_idx,\n","                     batch_size=batch_size,\n","                     vocab_size=vocab_size,\n","                     shuffle=True)\n","valid = TextIterator(valid_file, token_to_idx,\n","                     batch_size=batch_size,\n","                     vocab_size=vocab_size,\n","                     shuffle=False)\n","test = TextIterator(test_file, token_to_idx,\n","                    batch_size=batch_size,\n","                    vocab_size=vocab_size,\n","                    shuffle=False)\n","# Text iterator of training set for evaluation\n","train_eval = TextIterator(train_file, token_to_idx,\n","                          vocab_size=vocab_size, batch_size=batch_size, shuffle=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8VUKCqK_qO7","executionInfo":{"status":"ok","timestamp":1632624375534,"user_tz":-540,"elapsed":273,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_emb = nn.Embedding.from_pretrained(embedding)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJxx-wl-_5ln","executionInfo":{"status":"ok","timestamp":1632625118727,"user_tz":-540,"elapsed":309,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_c, test_c_mask, test_r, test_r_mask, test_target = prepare_data(train.next())"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HF5N-YliAJbc","executionInfo":{"status":"ok","timestamp":1632625164092,"user_tz":-540,"elapsed":297,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"f2b75192-f68d-40af-f0f5-1574963a2766"},"source":["print(test_c.shape)\n","print(test_c_mask.shape)\n","print(test_r.shape)\n","print(test_r_mask.shape)\n","print(test_target.shape)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["(96, 16)\n","(96, 16)\n","(41, 16)\n","(41, 16)\n","(16,)\n"]}]},{"cell_type":"code","metadata":{"id":"jUthg9gK_v67","executionInfo":{"status":"ok","timestamp":1632633228860,"user_tz":-540,"elapsed":287,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_c_emb = test_emb(torch.tensor(test_c, dtype=torch.int))\n","test_r_emb = test_emb(torch.tensor(test_r, dtype=torch.int))"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Fhog3VgHWJH","executionInfo":{"status":"ok","timestamp":1632633231307,"user_tz":-540,"elapsed":20,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"1f9a4204-4dd0-402f-cb5b-7388898c3559"},"source":["print(test_c_emb.shape)\n","print(test_r_emb.shape)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([96, 16, 300])\n","torch.Size([41, 16, 300])\n"]}]},{"cell_type":"code","metadata":{"id":"UFiUY584hh-E","executionInfo":{"status":"ok","timestamp":1632633471268,"user_tz":-540,"elapsed":318,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_dropout = nn.Dropout(p=1.0)\n","test_c_emb_drop = test_dropout(test_c_emb)\n","test_r_emb_drop = test_dropout(test_r_emb)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFMGiPRjbD2L","executionInfo":{"status":"ok","timestamp":1632633550837,"user_tz":-540,"elapsed":334,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_c_emb_last = test_c_emb_drop * torch.unsqueeze(torch.tensor(test_c_mask, dtype=torch.float32), -1)\n","test_r_emb_last = test_r_emb_drop * torch.unsqueeze(torch.tensor(test_r_mask, dtype=torch.float32), -1)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Opr1zEidZSC","executionInfo":{"status":"ok","timestamp":1632633560771,"user_tz":-540,"elapsed":317,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"033bbdff-ac1e-45e5-d9ed-3ffcb995ddbe"},"source":["print(test_c_emb_last.shape)\n","print(test_r_emb_last.shape)"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([96, 16, 300])\n","torch.Size([41, 16, 300])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZea5HPdl0L8","executionInfo":{"status":"ok","timestamp":1632634431563,"user_tz":-540,"elapsed":360,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"7fd006b7-6437-4fb9-b3e2-7b7e78bd33f4"},"source":["print(tuple(test_c_emb_last.shape))"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["(96, 16, 300)\n"]}]},{"cell_type":"code","metadata":{"id":"vXTjN-ZgkGI4","executionInfo":{"status":"ok","timestamp":1632639667633,"user_tz":-540,"elapsed":420,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_bilstm = nn.LSTM(dim_word, hidden_size=hidden_size * 2, bidirectional=True)"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bgZFuKP7VB1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oI7f5dak4EEq","executionInfo":{"status":"ok","timestamp":1632639763777,"user_tz":-540,"elapsed":299,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_c_enc, _ = test_bilstm(test_c_emb_last)\n","test_r_enc, _ = test_bilstm(test_r_emb_last)"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_9ryUkj4O99","executionInfo":{"status":"ok","timestamp":1632639760094,"user_tz":-540,"elapsed":305,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"ed9a36ac-35e2-4384-a12f-04159a655242"},"source":["test_c_enc.shape"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([96, 16, 1200])"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"DvFpCC_y6h2l","executionInfo":{"status":"ok","timestamp":1632639827986,"user_tz":-540,"elapsed":317,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["test_c_enc = test_c_enc * torch.unsqueeze(torch.tensor(test_c_mask, dtype=torch.float32), -1)\n","test_r_enc = test_r_enc * torch.unsqueeze(torch.tensor(test_r_mask, dtype=torch.float32), -1)"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMOmACmb6sl9","executionInfo":{"status":"ok","timestamp":1632639850405,"user_tz":-540,"elapsed":311,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"b9f2b699-9a36-48c5-aa65-3e509cee4bf4"},"source":["print(test_c_enc.shape)\n","print(test_r_enc.shape)"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([96, 16, 1200])\n","torch.Size([41, 16, 1200])\n"]}]},{"cell_type":"code","metadata":{"id":"MyQ-N3Lu9l06"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7m5Rrlw9vIe","executionInfo":{"status":"ok","timestamp":1632640712567,"user_tz":-540,"elapsed":4,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}}},"source":["c = torch.permute(test_c_enc, [1, 0, 2]).contiguous()\n","c_mask = torch.permute(torch.tensor(test_c_mask), [1, 0]).contiguous()\n","r = torch.permute(test_r_enc, [1, 0, 2]).contiguous()\n","r_mask = torch.permute(torch.tensor(test_r_mask), [1, 0]).contiguous()\n","\n","# attention_weight: [batch_size, seq_length1, seq_length2]\n","attention_weight = torch.matmul(c, torch.permute(r, [0, 2, 1]).contiguous())"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JgXu0s--Eyn","executionInfo":{"status":"ok","timestamp":1632640721731,"user_tz":-540,"elapsed":315,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"f2b5cf23-9bf9-44cd-e016-983c2df4da96"},"source":["attention_weight.shape"],"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 96, 41])"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0vWsTyE-PRq","executionInfo":{"status":"ok","timestamp":1632641420528,"user_tz":-540,"elapsed":324,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"df964ebd-296d-45f1-9093-8cc08cc0c1e9"},"source":["torch.max(attention_weight, , keepdim=True).values.shape"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 96, 41])"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZ6CZZGB9F-L","executionInfo":{"status":"ok","timestamp":1632640483351,"user_tz":-540,"elapsed":323,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"bb81ed2b-1a66-4d9a-bedc-04a585a597fc"},"source":["print(type(test_c_enc))\n","print(type(test_c_mask))\n","print(type(test_r_enc))\n","print(type(test_r_mask))"],"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","<class 'numpy.ndarray'>\n","<class 'torch.Tensor'>\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","metadata":{"id":"h2GTcGqU8h5r"},"source":["test_dual1, test_dual2 = local_inference(test_c_enc, torch.tensor(test_c_mask), test_r_enc, torch.tensor(test_r_mask))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cT2VRTwXS00B","executionInfo":{"status":"ok","timestamp":1632631470724,"user_tz":-540,"elapsed":316,"user":{"displayName":"moon Song","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04638093581814122146"}},"outputId":"145cdfa1-6739-4b21-ccae-7eec2208e45e"},"source":["torch.cuda.get_device_name(0)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"aKudwJgxx69y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mn_wuczY8SKu"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"y81pwBlb8RGj"},"source":["#model, loss_func, optimizer 선언\n","model = ESIM().to(devive)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","for epoch in range(epochs):\n","    while True:\n","        if train.next() is not None:\n","            for batch_idx, (c, c_mask, r, r_mask, l) in enumerate(train_loader):\n","                \n","                pred = model(c, c_mask, r, r_mask)\n","                loss = criterion(pred, l)\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","        else:\n","            break\n"],"execution_count":null,"outputs":[]}]}